{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting Room Occupancy based on Temperature, Humidity,Light and CO2**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset- https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+\n",
    "\n",
    "In this dataset, we have the following attributes\n",
    "\n",
    "date time year-month-day hour:minute:second  \n",
    "Temperature, in Celsius  \n",
    "Relative Humidity, %  \n",
    "Light, in L  \n",
    "CO2, in ppm  \n",
    "Humidity Ratio, Derived quantity from temperature and relative humidity, in kgwater-vapor/kg-air  \n",
    "Occupancy, 0 or 1, 0 for not occupied, 1 for occupied status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, GRU, Conv1D\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/prath/Downloads/occupancy.csv',  parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio',\n",
       "       'Occupancy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.to_numpy() #converting to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:,1:] #extracting all the columns except date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.7, 26.272, 585.2, 749.2, 0.004764163, 1],\n",
       "       [23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "       [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "       ...,\n",
       "       [24.33, 25.7, 817.0, 1125.8, 0.004840759, 1],\n",
       "       [24.35666667, 25.7, 813.0, 1123.0, 0.004848559, 1],\n",
       "       [24.40833333, 25.68166667, 798.0, 1124.0, 0.004860208, 1]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2665, 6)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    obs = []\n",
    "    print(obs)    \n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        obs.append(data[i:(i+seq_length)+1])\n",
    "    return np.array(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a sequence of 5 as we have 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[23.7, 26.272, 585.2, 749.2, 0.004764163, 1],\n",
       "        [23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "        [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "        [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1]],\n",
       "\n",
       "       [[23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "        [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "        [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1],\n",
       "        [23.73, 26.29, 536.3333333, 798.0, 0.004776136, 1]],\n",
       "\n",
       "       [[23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "        [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1],\n",
       "        [23.73, 26.29, 536.3333333, 798.0, 0.004776136, 1],\n",
       "        [23.754, 26.29, 509.0, 797.0, 0.004783094, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[24.218, 25.912, 805.0, 1152.4, 0.004848089, 1],\n",
       "        [24.26, 25.89166667, 798.0, 1146.166667, 0.004856565, 1],\n",
       "        [24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1],\n",
       "        [24.33, 25.736, 809.8, 1129.2, 0.004847592, 1]],\n",
       "\n",
       "       [[24.26, 25.89166667, 798.0, 1146.166667, 0.004856565, 1],\n",
       "        [24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1],\n",
       "        [24.33, 25.736, 809.8, 1129.2, 0.004847592, 1],\n",
       "        [24.33, 25.7, 817.0, 1125.8, 0.004840759, 1]],\n",
       "\n",
       "       [[24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1],\n",
       "        [24.33, 25.736, 809.8, 1129.2, 0.004847592, 1],\n",
       "        [24.33, 25.7, 817.0, 1125.8, 0.004840759, 1],\n",
       "        [24.35666667, 25.7, 813.0, 1123.0, 0.004848559, 1]]], dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_input = create_sequences(data, 5)\n",
    "RNN_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.7, 26.272, 585.2, 749.2, 0.004764163, 1],\n",
       "       [23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "       [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "       [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "       [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "       [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1]], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = RNN_input[:,-1,-1] # the last column of the last row is our target variable which is occupancy\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[23.7, 26.272, 585.2, 749.2, 0.004764163, 1],\n",
       "        [23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "        [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1]],\n",
       "\n",
       "       [[23.718, 26.29, 578.4, 760.4, 0.004772661, 1],\n",
       "        [23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "        [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1]],\n",
       "\n",
       "       [[23.73, 26.23, 572.6666667, 769.6666667, 0.004765153, 1],\n",
       "        [23.7225, 26.125, 493.75, 774.75, 0.004743773, 1],\n",
       "        [23.754, 26.2, 488.6, 779.0, 0.004766594, 1],\n",
       "        [23.76, 26.26, 568.6666667, 790.0, 0.004779332, 1],\n",
       "        [23.73, 26.29, 536.3333333, 798.0, 0.004776136, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[24.218, 25.912, 805.0, 1152.4, 0.004848089, 1],\n",
       "        [24.26, 25.89166667, 798.0, 1146.166667, 0.004856565, 1],\n",
       "        [24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1]],\n",
       "\n",
       "       [[24.26, 25.89166667, 798.0, 1146.166667, 0.004856565, 1],\n",
       "        [24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1],\n",
       "        [24.33, 25.736, 809.8, 1129.2, 0.004847592, 1]],\n",
       "\n",
       "       [[24.29, 25.978, 793.0, 1145.4, 0.004881725, 1],\n",
       "        [24.29, 25.852, 801.4, 1140.8, 0.004857863, 1],\n",
       "        [24.29, 25.7, 808.0, 1150.25, 0.004829079, 1],\n",
       "        [24.33, 25.736, 809.8, 1129.2, 0.004847592, 1],\n",
       "        [24.33, 25.7, 817.0, 1125.8, 0.004840759, 1]]], dtype=object)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = RNN_input[:,0:5,0:6] # getting all the rows except last one which will be used for training\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train to Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=object)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=object)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2127, 5, 6)\n",
      "(532, 5, 6)\n",
      "(2127, 1)\n",
      "(532, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[20.365, 22.5, 0.0, 436.5, 0.003321598, 0],\n",
       "        [20.39, 22.5, 0.0, 434.0, 0.003326758, 0],\n",
       "        [20.39, 22.5, 0.0, 435.25, 0.003326758, 0],\n",
       "        [20.39, 22.5, 0.0, 432.75, 0.003326758, 0],\n",
       "        [20.39, 22.5, 0.0, 432.0, 0.003326758, 0]],\n",
       "\n",
       "       [[21.2, 27.6, 0.0, 758.5, 0.004296136, 0],\n",
       "        [21.2, 27.575, 0.0, 749.75, 0.004292217, 0],\n",
       "        [21.2, 27.6, 0.0, 749.0, 0.004296136, 0],\n",
       "        [21.2, 27.54, 0.0, 747.8, 0.004286732, 0],\n",
       "        [21.2, 27.5, 0.0, 744.0, 0.004280463, 0]],\n",
       "\n",
       "       [[21.175, 25.04041667, 446.6666667, 751.5, 0.003889213, 1],\n",
       "        [21.15, 24.9175, 449.3333333, 750.3333333, 0.003864032, 1],\n",
       "        [21.18333333, 25.19833333, 454.6666667, 754.3333333, 0.00391591,\n",
       "         1],\n",
       "        [21.2, 25.34, 448.0, 765.75, 0.003942121, 1],\n",
       "        [21.2, 25.3925, 454.75, 782.0, 0.00395034, 1]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[21.1, 24.89, 444.0, 740.8, 0.003847834, 1],\n",
       "        [21.13333333, 24.82333333, 444.0, 747.3333333, 0.003845377, 0],\n",
       "        [21.16666667, 24.85833333, 444.0, 745.5, 0.00385877, 0],\n",
       "        [21.2, 25.16333333, 444.0, 752.6666667, 0.003914464, 1],\n",
       "        [21.175, 25.04041667, 446.6666667, 751.5, 0.003889213, 1]],\n",
       "\n",
       "       [[22.2, 27.54, 538.6, 1093.2, 0.004558974, 1],\n",
       "        [22.2, 27.56666667, 549.3333333, 1102.5, 0.004563421, 1],\n",
       "        [22.2, 27.52, 548.6, 1104.4, 0.004555639, 1],\n",
       "        [22.2, 27.58, 543.0, 1101.75, 0.004565644, 1],\n",
       "        [22.2, 27.6, 548.5, 1098.75, 0.004568979, 1]],\n",
       "\n",
       "       [[20.39, 22.5, 0.0, 431.5, 0.003326758, 0],\n",
       "        [20.39, 22.5, 0.0, 432.5, 0.003326758, 0],\n",
       "        [20.39, 22.456, 0.0, 435.4, 0.003320218, 0],\n",
       "        [20.39, 22.5, 0.0, 436.6666667, 0.003326758, 0],\n",
       "        [20.39, 22.5, 0.0, 432.6, 0.003326758, 0]]], dtype=object)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Neural Networks are scale sensitive, it is better to rescale them for appropriate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = X_scaler.fit_transform(X_train.reshape(-1, 6))\n",
    "X_test_scaled = X_scaler.transform(X_test.reshape(-1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=X_train_scaled.reshape(-1, 5, 6)\n",
    "X_test_scaled=X_test_scaled.reshape(-1, 5, 6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 5, 64)             18176     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 5, 32)             12416     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,945\n",
      "Trainable params: 38,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        LSTM(64,return_sequences=True, input_shape=[5, 6]),\n",
    "        LSTM(32, return_sequences=True),\n",
    "        LSTM(32,return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 4s 17ms/step - loss: 0.3428 - accuracy: 0.9450 - val_loss: 0.1249 - val_accuracy: 0.9699\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.1053 - accuracy: 0.9732 - val_loss: 0.1190 - val_accuracy: 0.9699\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0988 - accuracy: 0.9756 - val_loss: 0.1168 - val_accuracy: 0.9718\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0921 - accuracy: 0.9751 - val_loss: 0.1148 - val_accuracy: 0.9699\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0860 - accuracy: 0.9770 - val_loss: 0.1077 - val_accuracy: 0.9718\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9774 - val_loss: 0.1012 - val_accuracy: 0.9756\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9784 - val_loss: 0.0998 - val_accuracy: 0.9793\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0724 - accuracy: 0.9784 - val_loss: 0.1011 - val_accuracy: 0.9793\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0705 - accuracy: 0.9788 - val_loss: 0.0960 - val_accuracy: 0.9774\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0660 - accuracy: 0.9803 - val_loss: 0.0940 - val_accuracy: 0.9774\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0637 - accuracy: 0.9812 - val_loss: 0.0926 - val_accuracy: 0.9793\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9817 - val_loss: 0.0864 - val_accuracy: 0.9812\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 0.0811 - val_accuracy: 0.9812\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0569 - accuracy: 0.9840 - val_loss: 0.0880 - val_accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 0.0884 - val_accuracy: 0.9662\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0551 - accuracy: 0.9840 - val_loss: 0.0758 - val_accuracy: 0.9831\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0872 - val_accuracy: 0.9793\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0522 - accuracy: 0.9850 - val_loss: 0.0864 - val_accuracy: 0.9831\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9854 - val_loss: 0.0809 - val_accuracy: 0.9699\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.9859 - val_loss: 0.0729 - val_accuracy: 0.9812\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9850\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0467 - accuracy: 0.9868 - val_loss: 0.0676 - val_accuracy: 0.9850\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0457 - accuracy: 0.9878 - val_loss: 0.0693 - val_accuracy: 0.9850\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.0617 - val_accuracy: 0.9850\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 0.0593 - val_accuracy: 0.9868\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9906 - val_loss: 0.0740 - val_accuracy: 0.9868\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9911 - val_loss: 0.0571 - val_accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0409 - accuracy: 0.9906 - val_loss: 0.0581 - val_accuracy: 0.9868\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9897 - val_loss: 0.0591 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9897 - val_loss: 0.0601 - val_accuracy: 0.9868\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0415 - accuracy: 0.9892 - val_loss: 0.0573 - val_accuracy: 0.9887\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0401 - accuracy: 0.9897 - val_loss: 0.0600 - val_accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9901 - val_loss: 0.0610 - val_accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9906 - val_loss: 0.0568 - val_accuracy: 0.9868\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.0578 - val_accuracy: 0.9868\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0394 - accuracy: 0.9901 - val_loss: 0.0621 - val_accuracy: 0.9868\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 0.0617 - val_accuracy: 0.9868\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9901 - val_loss: 0.0619 - val_accuracy: 0.9868\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.0560 - val_accuracy: 0.9887\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.0751 - val_accuracy: 0.9868\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0402 - accuracy: 0.9911 - val_loss: 0.0599 - val_accuracy: 0.9868\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9901 - val_loss: 0.0556 - val_accuracy: 0.9887\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0401 - accuracy: 0.9897 - val_loss: 0.0576 - val_accuracy: 0.9868\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9911 - val_loss: 0.0564 - val_accuracy: 0.9887\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.0559 - val_accuracy: 0.9887\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0388 - accuracy: 0.9901 - val_loss: 0.0554 - val_accuracy: 0.9906\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9897 - val_loss: 0.0625 - val_accuracy: 0.9887\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0394 - accuracy: 0.9901 - val_loss: 0.0565 - val_accuracy: 0.9906\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0376 - accuracy: 0.9901 - val_loss: 0.0567 - val_accuracy: 0.9906\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.0600 - val_accuracy: 0.9868\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0580 - val_accuracy: 0.9868\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.0632 - val_accuracy: 0.9868\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9901 - val_loss: 0.0606 - val_accuracy: 0.9868\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0579 - val_accuracy: 0.9906\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0374 - accuracy: 0.9906 - val_loss: 0.0657 - val_accuracy: 0.9850\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0563 - val_accuracy: 0.9906\n",
      "Epoch 57: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta = 0.0, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_test_scaled, y_test), \n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the results to have binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted  residual\n",
       "0         0          0         0\n",
       "1         1          1         0\n",
       "2         1          1         0\n",
       "3         1          1         0\n",
       "4         0          0         0\n",
       "..      ...        ...       ...\n",
       "527       1          1         0\n",
       "528       1          1         0\n",
       "529       0          0         0\n",
       "530       1          1         0\n",
       "531       0          0         0\n",
       "\n",
       "[532 rows x 3 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test.flatten()\n",
    "results['predicted'] = y_pred_binary.flatten()\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906015037593985"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_15 (GRU)                (None, 5, 64)             13824     \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 5, 32)             9408      \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 16)                2400      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,649\n",
      "Trainable params: 25,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        GRU(64,return_sequences=True, input_shape=[5, 6]),\n",
    "        GRU(32, return_sequences=True),\n",
    "        GRU(16,return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer='sgd', \n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 4s 15ms/step - loss: 0.6418 - accuracy: 0.6380 - val_loss: 0.5794 - val_accuracy: 0.7162\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.8655 - val_loss: 0.4476 - val_accuracy: 0.9586\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.9751 - val_loss: 0.3104 - val_accuracy: 0.9774\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.2526 - accuracy: 0.9751 - val_loss: 0.2098 - val_accuracy: 0.9774\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.1749 - accuracy: 0.9779 - val_loss: 0.1544 - val_accuracy: 0.9774\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.9774 - val_loss: 0.1255 - val_accuracy: 0.9793\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.1120 - accuracy: 0.9774 - val_loss: 0.1097 - val_accuracy: 0.9793\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9779 - val_loss: 0.1009 - val_accuracy: 0.9793\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0933 - accuracy: 0.9793 - val_loss: 0.0956 - val_accuracy: 0.9793\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 0.9784 - val_loss: 0.0922 - val_accuracy: 0.9793\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9784 - val_loss: 0.0900 - val_accuracy: 0.9793\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9788 - val_loss: 0.0886 - val_accuracy: 0.9793\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9788 - val_loss: 0.0875 - val_accuracy: 0.9793\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9788 - val_loss: 0.0866 - val_accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9788 - val_loss: 0.0860 - val_accuracy: 0.9793\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.9779 - val_loss: 0.0855 - val_accuracy: 0.9793\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9784 - val_loss: 0.0851 - val_accuracy: 0.9793\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0803 - accuracy: 0.9788 - val_loss: 0.0849 - val_accuracy: 0.9793\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9779 - val_loss: 0.0845 - val_accuracy: 0.9774\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9788 - val_loss: 0.0842 - val_accuracy: 0.9774\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9774\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9784 - val_loss: 0.0837 - val_accuracy: 0.9774\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9788 - val_loss: 0.0836 - val_accuracy: 0.9774\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9784 - val_loss: 0.0833 - val_accuracy: 0.9774\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9784 - val_loss: 0.0831 - val_accuracy: 0.9774\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9784 - val_loss: 0.0829 - val_accuracy: 0.9774\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9779 - val_loss: 0.0828 - val_accuracy: 0.9774\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9784 - val_loss: 0.0825 - val_accuracy: 0.9774\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9779 - val_loss: 0.0824 - val_accuracy: 0.9774\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0775 - accuracy: 0.9779 - val_loss: 0.0822 - val_accuracy: 0.9774\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9784 - val_loss: 0.0820 - val_accuracy: 0.9774\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9784 - val_loss: 0.0819 - val_accuracy: 0.9774\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9784 - val_loss: 0.0817 - val_accuracy: 0.9774\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0767 - accuracy: 0.9784 - val_loss: 0.0816 - val_accuracy: 0.9774\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0765 - accuracy: 0.9779 - val_loss: 0.0814 - val_accuracy: 0.9774\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0763 - accuracy: 0.9784 - val_loss: 0.0813 - val_accuracy: 0.9774\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0760 - accuracy: 0.9779 - val_loss: 0.0811 - val_accuracy: 0.9793\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0759 - accuracy: 0.9788 - val_loss: 0.0810 - val_accuracy: 0.9793\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0757 - accuracy: 0.9784 - val_loss: 0.0808 - val_accuracy: 0.9793\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0755 - accuracy: 0.9784 - val_loss: 0.0807 - val_accuracy: 0.9793\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9784 - val_loss: 0.0805 - val_accuracy: 0.9793\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0751 - accuracy: 0.9788 - val_loss: 0.0804 - val_accuracy: 0.9793\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9793 - val_loss: 0.0802 - val_accuracy: 0.9793\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0748 - accuracy: 0.9793 - val_loss: 0.0801 - val_accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0746 - accuracy: 0.9793 - val_loss: 0.0800 - val_accuracy: 0.9793\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9788 - val_loss: 0.0799 - val_accuracy: 0.9793\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9803 - val_loss: 0.0797 - val_accuracy: 0.9793\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9803 - val_loss: 0.0796 - val_accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0738 - accuracy: 0.9793 - val_loss: 0.0795 - val_accuracy: 0.9793\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9798 - val_loss: 0.0794 - val_accuracy: 0.9793\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0735 - accuracy: 0.9803 - val_loss: 0.0792 - val_accuracy: 0.9793\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0733 - accuracy: 0.9803 - val_loss: 0.0791 - val_accuracy: 0.9793\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0732 - accuracy: 0.9807 - val_loss: 0.0789 - val_accuracy: 0.9793\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.0788 - val_accuracy: 0.9793\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0787 - val_accuracy: 0.9793\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0727 - accuracy: 0.9803 - val_loss: 0.0786 - val_accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0724 - accuracy: 0.9807 - val_loss: 0.0784 - val_accuracy: 0.9793\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0722 - accuracy: 0.9803 - val_loss: 0.0783 - val_accuracy: 0.9793\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.0782 - val_accuracy: 0.9793\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0719 - accuracy: 0.9807 - val_loss: 0.0781 - val_accuracy: 0.9793\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0717 - accuracy: 0.9807 - val_loss: 0.0780 - val_accuracy: 0.9793\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0716 - accuracy: 0.9807 - val_loss: 0.0778 - val_accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0713 - accuracy: 0.9803 - val_loss: 0.0777 - val_accuracy: 0.9793\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0712 - accuracy: 0.9807 - val_loss: 0.0776 - val_accuracy: 0.9793\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.0775 - val_accuracy: 0.9793\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9803 - val_loss: 0.0774 - val_accuracy: 0.9793\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9807 - val_loss: 0.0772 - val_accuracy: 0.9793\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0705 - accuracy: 0.9803 - val_loss: 0.0772 - val_accuracy: 0.9812\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0703 - accuracy: 0.9807 - val_loss: 0.0770 - val_accuracy: 0.9793\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0702 - accuracy: 0.9807 - val_loss: 0.0769 - val_accuracy: 0.9812\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0699 - accuracy: 0.9807 - val_loss: 0.0767 - val_accuracy: 0.9812\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0698 - accuracy: 0.9807 - val_loss: 0.0766 - val_accuracy: 0.9793\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.0765 - val_accuracy: 0.9812\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0695 - accuracy: 0.9807 - val_loss: 0.0764 - val_accuracy: 0.9812\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0692 - accuracy: 0.9807 - val_loss: 0.0763 - val_accuracy: 0.9812\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0692 - accuracy: 0.9807 - val_loss: 0.0761 - val_accuracy: 0.9812\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9807 - val_loss: 0.0761 - val_accuracy: 0.9812\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9807 - val_loss: 0.0759 - val_accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9807 - val_loss: 0.0758 - val_accuracy: 0.9812\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0684 - accuracy: 0.9807 - val_loss: 0.0757 - val_accuracy: 0.9812\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9803 - val_loss: 0.0756 - val_accuracy: 0.9812\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9807 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9803 - val_loss: 0.0753 - val_accuracy: 0.9812\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9803 - val_loss: 0.0752 - val_accuracy: 0.9812\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0676 - accuracy: 0.9807 - val_loss: 0.0751 - val_accuracy: 0.9812\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0675 - accuracy: 0.9803 - val_loss: 0.0750 - val_accuracy: 0.9812\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 0.0749 - val_accuracy: 0.9812\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0671 - accuracy: 0.9803 - val_loss: 0.0748 - val_accuracy: 0.9812\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 0.0747 - val_accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9803 - val_loss: 0.0746 - val_accuracy: 0.9812\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9803 - val_loss: 0.0744 - val_accuracy: 0.9812\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0664 - accuracy: 0.9803 - val_loss: 0.0743 - val_accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0662 - accuracy: 0.9807 - val_loss: 0.0742 - val_accuracy: 0.9812\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0661 - accuracy: 0.9803 - val_loss: 0.0741 - val_accuracy: 0.9831\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9803 - val_loss: 0.0740 - val_accuracy: 0.9831\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9803 - val_loss: 0.0739 - val_accuracy: 0.9831\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9807 - val_loss: 0.0739 - val_accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9807 - val_loss: 0.0736 - val_accuracy: 0.9831\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9803 - val_loss: 0.0735 - val_accuracy: 0.9831\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0651 - accuracy: 0.9812 - val_loss: 0.0734 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta = 0.0, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_test_scaled, y_test), \n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted  residual\n",
       "0         0          0         0\n",
       "1         1          1         0\n",
       "2         1          1         0\n",
       "3         1          1         0\n",
       "4         0          0         0\n",
       "..      ...        ...       ...\n",
       "527       1          1         0\n",
       "528       1          1         0\n",
       "529       0          0         0\n",
       "530       1          1         0\n",
       "531       0          0         0\n",
       "\n",
       "[532 rows x 3 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test.flatten()\n",
    "results['predicted'] = y_pred_binary.flatten()\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830827067669173"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the two recurrent models I have fit on the data i.e., LSTM and GRU. LSTM fit the data better than GRU with an accuracy of 0.99. There is not much difference in the performance. Even GRU has an accuracy of 0.98"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
