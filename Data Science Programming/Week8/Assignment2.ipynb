{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2313325d",
   "metadata": {},
   "source": [
    "# Risk Factor prediction of Chronic Kidney Disease Data Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03537784",
   "metadata": {},
   "source": [
    "Dataset link - https://archive.ics.uci.edu/ml/datasets/Risk+Factor+prediction+of+Chronic+Kidney+Disease#\n",
    "\n",
    "I selected this dataset from UCI ML Repository. This dataset contains the patients data who were affected by chronic kidney disease. \n",
    "Following are the columns in the dataset-\n",
    "1. bp(Diastolic)\n",
    "2. bp limit\n",
    "3. sg\n",
    "4. al\n",
    "5. class\n",
    "6. rbc\n",
    "7. su\n",
    "8. pc\n",
    "9. pcc\n",
    "10. ba\n",
    "11. bgr\n",
    "12. bu\n",
    "13. sod\n",
    "14. sc\n",
    "15. pot\n",
    "16. hemo\n",
    "17. pcv\n",
    "18. rbcc\n",
    "19. wbcc\n",
    "20. htn\n",
    "21. dm\n",
    "22. cad\n",
    "23. appet\n",
    "24. pe\n",
    "25. ane\n",
    "26. grf\n",
    "27. stage\n",
    "28. affected\n",
    "29. age\n",
    "\n",
    "For this dataset, I preprocessed the data first as it has noise,then did the split of data and addressed the data imbalance. Later on fitted the ML models on the resulting dataset. \n",
    "\n",
    "Since this is a Classification problem, I chose Logistic Regression, Decision Tree, Random Forest, AdaBoost and Gradient Boost models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3262a",
   "metadata": {},
   "source": [
    "**Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6599a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864bdb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc48d99",
   "metadata": {},
   "source": [
    "**Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58c2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd=pd.read_csv(\"C:/Users/prath/Downloads/ckd-dataset-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050f52b",
   "metadata": {},
   "source": [
    "**Exploring data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d15aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp (Diastolic)</th>\n",
       "      <th>bp limit</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>class</th>\n",
       "      <th>rbc</th>\n",
       "      <th>su</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>grf</th>\n",
       "      <th>stage</th>\n",
       "      <th>affected</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.019 - 1.021</td>\n",
       "      <td>1-Jan</td>\n",
       "      <td>ckd</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>≥ 227.944</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009 - 1.011</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>ckd</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>≥ 227.944</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009 - 1.011</td>\n",
       "      <td>≥ 4</td>\n",
       "      <td>ckd</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.281 - 152.446</td>\n",
       "      <td>s1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bp (Diastolic)  bp limit             sg     al class  rbc   su  pc  pcc   \n",
       "0               0         0  1.019 - 1.021  1-Jan   ckd    0  < 0   0    0  \\\n",
       "1               0         0  1.009 - 1.011    < 0   ckd    0  < 0   0    0   \n",
       "2               0         0  1.009 - 1.011    ≥ 4   ckd    1  < 0   1    0   \n",
       "\n",
       "   ba  ... htn dm cad appet pe ane                grf stage affected   age  \n",
       "0   0  ...   0  0   0     0  0   0          ≥ 227.944    s1        1  < 12  \n",
       "1   0  ...   0  0   0     0  0   0          ≥ 227.944    s1        1  < 12  \n",
       "2   1  ...   0  0   0     1  0   0  127.281 - 152.446    s1        1  < 12  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6123c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 29 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   bp (Diastolic)  200 non-null    int64 \n",
      " 1   bp limit        200 non-null    int64 \n",
      " 2   sg              200 non-null    object\n",
      " 3   al              200 non-null    object\n",
      " 4   class           200 non-null    object\n",
      " 5   rbc             200 non-null    int64 \n",
      " 6   su              200 non-null    object\n",
      " 7   pc              200 non-null    int64 \n",
      " 8   pcc             200 non-null    int64 \n",
      " 9   ba              200 non-null    int64 \n",
      " 10  bgr             200 non-null    object\n",
      " 11  bu              200 non-null    object\n",
      " 12  sod             200 non-null    object\n",
      " 13  sc              200 non-null    object\n",
      " 14  pot             200 non-null    object\n",
      " 15  hemo            200 non-null    object\n",
      " 16  pcv             200 non-null    object\n",
      " 17  rbcc            200 non-null    object\n",
      " 18  wbcc            200 non-null    object\n",
      " 19  htn             200 non-null    int64 \n",
      " 20  dm              200 non-null    int64 \n",
      " 21  cad             200 non-null    int64 \n",
      " 22  appet           200 non-null    int64 \n",
      " 23  pe              200 non-null    int64 \n",
      " 24  ane             200 non-null    int64 \n",
      " 25  grf             200 non-null    object\n",
      " 26  stage           200 non-null    object\n",
      " 27  affected        200 non-null    int64 \n",
      " 28  age             200 non-null    object\n",
      "dtypes: int64(13), object(16)\n",
      "memory usage: 45.4+ KB\n"
     ]
    }
   ],
   "source": [
    "ckd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddacb27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp (Diastolic)</th>\n",
       "      <th>bp limit</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>affected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.805119</td>\n",
       "      <td>0.331549</td>\n",
       "      <td>0.41863</td>\n",
       "      <td>0.342581</td>\n",
       "      <td>0.228552</td>\n",
       "      <td>0.488974</td>\n",
       "      <td>0.478167</td>\n",
       "      <td>0.313675</td>\n",
       "      <td>0.401004</td>\n",
       "      <td>0.380921</td>\n",
       "      <td>0.367526</td>\n",
       "      <td>0.481205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bp (Diastolic)    bp limit         rbc         pc         pcc   \n",
       "count      200.000000  200.000000  200.000000  200.00000  200.000000  \\\n",
       "mean         0.540000    0.755000    0.125000    0.22500    0.135000   \n",
       "std          0.499648    0.805119    0.331549    0.41863    0.342581   \n",
       "min          0.000000    0.000000    0.000000    0.00000    0.000000   \n",
       "25%          0.000000    0.000000    0.000000    0.00000    0.000000   \n",
       "50%          1.000000    1.000000    0.000000    0.00000    0.000000   \n",
       "75%          1.000000    1.000000    0.000000    0.00000    0.000000   \n",
       "max          1.000000    2.000000    1.000000    1.00000    1.000000   \n",
       "\n",
       "               ba         htn          dm         cad       appet          pe   \n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000  \\\n",
       "mean     0.055000    0.390000    0.350000    0.110000    0.200000    0.175000   \n",
       "std      0.228552    0.488974    0.478167    0.313675    0.401004    0.380921   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              ane    affected  \n",
       "count  200.000000  200.000000  \n",
       "mean     0.160000    0.640000  \n",
       "std      0.367526    0.481205  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      0.000000    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b66c99",
   "metadata": {},
   "source": [
    "Checking for Null Value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d9d8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bp (Diastolic)    0\n",
       "bp limit          0\n",
       "sg                0\n",
       "al                0\n",
       "class             0\n",
       "rbc               0\n",
       "su                0\n",
       "pc                0\n",
       "pcc               0\n",
       "ba                0\n",
       "bgr               0\n",
       "bu                0\n",
       "sod               0\n",
       "sc                0\n",
       "pot               0\n",
       "hemo              0\n",
       "pcv               0\n",
       "rbcc              0\n",
       "wbcc              0\n",
       "htn               0\n",
       "dm                0\n",
       "cad               0\n",
       "appet             0\n",
       "pe                0\n",
       "ane               0\n",
       "grf               0\n",
       "stage             0\n",
       "affected          0\n",
       "age               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b7b5e",
   "metadata": {},
   "source": [
    "List of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ebe3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sg',\n",
       " 'al',\n",
       " 'class',\n",
       " 'su',\n",
       " 'bgr',\n",
       " 'bu',\n",
       " 'sod',\n",
       " 'sc',\n",
       " 'pot',\n",
       " 'hemo',\n",
       " 'pcv',\n",
       " 'rbcc',\n",
       " 'wbcc',\n",
       " 'grf',\n",
       " 'stage',\n",
       " 'age']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_var_list = list(ckd.select_dtypes(include='object').columns)\n",
    "category_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7658b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: sg Values: ['1.019 - 1.021' '1.009 - 1.011' '1.015 - 1.017' '≥ 1.023' '< 1.007']\n",
      "Category: al Values: ['1-Jan' '< 0' '≥ 4' '3-Mar' '2-Feb']\n",
      "Category: class Values: ['ckd' 'notckd']\n",
      "Category: su Values: ['< 0' '4-Apr' '2-Feb' '4-Mar' '2-Jan' '≥ 4']\n",
      "Category: bgr Values: ['< 112' '112 - 154' '154 - 196' '406 - 448' '238 - 280' '196 - 238'\n",
      " '≥ 448' '280 - 322' '364 - 406' '322 - 364']\n",
      "Category: bu Values: ['< 48.1' '48.1 - 86.2' '200.5 - 238.6' '124.3 - 162.4' '86.2 - 124.3'\n",
      " '162.4 - 200.5' '≥ 352.9' '238.6 - 276.7']\n",
      "Category: sod Values: ['138 - 143' '133 - 138' '123 - 128' '143 - 148' '148 - 153' '< 118'\n",
      " '128 - 133' '118 - 123' '≥ 158']\n",
      "Category: sc Values: ['< 3.65' '3.65 - 6.8' '16.25 - 19.4' '6.8 - 9.95' '13.1 - 16.25'\n",
      " '9.95 - 13.1' '≥ 28.85']\n",
      "Category: pot Values: ['< 7.31' '≥ 42.59' '7.31 - 11.72' '38.18 - 42.59']\n",
      "Category: hemo Values: ['11.3 - 12.6' '8.7 - 10' '13.9 - 15.2' '≥ 16.5' '10 - 11.3' '7.4 - 8.7'\n",
      " '12.6 - 13.9' '15.2 - 16.5' '< 6.1' '6.1 - 7.4']\n",
      "Category: pcv Values: ['33.5 - 37.4' '29.6 - 33.5' '41.3 - 45.2' '37.4 - 41.3' '≥ 49.1'\n",
      " '21.8 - 25.7' '45.2 - 49.1' '< 17.9' '25.7 - 29.6' '17.9 - 21.8']\n",
      "Category: rbcc Values: ['4.46 - 5.05' '5.05 - 5.64' '3.28 - 3.87' '3.87 - 4.46' '6.23 - 6.82'\n",
      " '5.64 - 6.23' '2.69 - 3.28' '< 2.69' '≥ 7.41']\n",
      "Category: wbcc Values: ['7360 - 9740' '12120 - 14500' '14500 - 16880' '4980 - 7360' '< 4980'\n",
      " '9740 - 12120' '16880 - 19260' '≥ 24020' '19260 - 21640']\n",
      "Category: grf Values: ['≥ 227.944' '127.281 - 152.446' '102.115 - 127.281' '177.612 - 202.778'\n",
      " '26.6175 - 51.7832' '51.7832 - 76.949' '76.949 - 102.115'\n",
      " '152.446 - 177.612' '202.778 - 227.944' '< 26.6175' ' p ']\n",
      "Category: stage Values: ['s1' 's4' 's3' 's2' 's5']\n",
      "Category: age Values: ['< 12' '20-Dec' '20 - 27' '27 - 35' '35 - 43' '43 - 51' '51 - 59'\n",
      " '59 - 66' '66 - 74' '≥ 74']\n"
     ]
    }
   ],
   "source": [
    "#to get the unique values in each column\n",
    "for cat in category_var_list: \n",
    "    print(f\"Category: {cat} Values: {ckd[cat].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1adb8",
   "metadata": {},
   "source": [
    "It is observed that there are some irrelevant values in some columns, so it's better replace them with Nan and remove the class column since it's directly correlated to our target variable 'affected'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899bdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd.drop(['class'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc799794",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['al']=ckd.al.replace(['1-Jan','3-Mar','2-Feb'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2ae88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['su']=ckd.su.replace(['4-Apr','2-Feb','4-Mar','2-Jan'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d198c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['grf']=ckd.grf.replace([' p '],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d3cf343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd['age']=ckd.age.replace(['20-Dec'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69063cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bp (Diastolic)     0\n",
       "bp limit           0\n",
       "sg                 0\n",
       "al                71\n",
       "rbc                0\n",
       "su                29\n",
       "pc                 0\n",
       "pcc                0\n",
       "ba                 0\n",
       "bgr                0\n",
       "bu                 0\n",
       "sod                0\n",
       "sc                 0\n",
       "pot                0\n",
       "hemo               0\n",
       "pcv                0\n",
       "rbcc               0\n",
       "wbcc               0\n",
       "htn                0\n",
       "dm                 0\n",
       "cad                0\n",
       "appet              0\n",
       "pe                 0\n",
       "ane                0\n",
       "grf                1\n",
       "stage              0\n",
       "affected           0\n",
       "age                4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nan values\n",
    "ckd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "976a16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the Nan values with mode\n",
    "ckd['al']=ckd.al.fillna(ckd.al.mode())\n",
    "ckd['su']=ckd.su.fillna(ckd.su.mode())\n",
    "ckd['grf']=ckd.grf.fillna(ckd.grf.mode())\n",
    "ckd['age']=ckd.age.fillna(ckd.age.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bebaa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoding the categorical columns since the models can only work with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9740324",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "ckd['sg'] = labelencoder.fit_transform(ckd['sg'])\n",
    "ckd['al'] = labelencoder.fit_transform(ckd['al'])\n",
    "ckd['su'] = labelencoder.fit_transform(ckd['su'])\n",
    "ckd['bgr'] = labelencoder.fit_transform(ckd['bgr'])\n",
    "ckd['bu'] = labelencoder.fit_transform(ckd['bu'])\n",
    "ckd['sod'] = labelencoder.fit_transform(ckd['sod'])\n",
    "ckd['sc'] = labelencoder.fit_transform(ckd['sc'])\n",
    "ckd['pot'] = labelencoder.fit_transform(ckd['pot'])\n",
    "ckd['hemo'] = labelencoder.fit_transform(ckd['hemo'])\n",
    "ckd['pcv'] = labelencoder.fit_transform(ckd['pcv'])\n",
    "ckd['rbcc'] = labelencoder.fit_transform(ckd['rbcc'])\n",
    "ckd['wbcc'] = labelencoder.fit_transform(ckd['wbcc'])\n",
    "ckd['grf'] = labelencoder.fit_transform(ckd['grf'])\n",
    "ckd['stage'] = labelencoder.fit_transform(ckd['stage'])\n",
    "ckd['age'] = labelencoder.fit_transform(ckd['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00dfbb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   bp (Diastolic)  200 non-null    int64\n",
      " 1   bp limit        200 non-null    int64\n",
      " 2   sg              200 non-null    int32\n",
      " 3   al              200 non-null    int32\n",
      " 4   rbc             200 non-null    int64\n",
      " 5   su              200 non-null    int32\n",
      " 6   pc              200 non-null    int64\n",
      " 7   pcc             200 non-null    int64\n",
      " 8   ba              200 non-null    int64\n",
      " 9   bgr             200 non-null    int32\n",
      " 10  bu              200 non-null    int32\n",
      " 11  sod             200 non-null    int32\n",
      " 12  sc              200 non-null    int32\n",
      " 13  pot             200 non-null    int32\n",
      " 14  hemo            200 non-null    int32\n",
      " 15  pcv             200 non-null    int32\n",
      " 16  rbcc            200 non-null    int32\n",
      " 17  wbcc            200 non-null    int32\n",
      " 18  htn             200 non-null    int64\n",
      " 19  dm              200 non-null    int64\n",
      " 20  cad             200 non-null    int64\n",
      " 21  appet           200 non-null    int64\n",
      " 22  pe              200 non-null    int64\n",
      " 23  ane             200 non-null    int64\n",
      " 24  grf             200 non-null    int32\n",
      " 25  stage           200 non-null    int32\n",
      " 26  affected        200 non-null    int64\n",
      " 27  age             200 non-null    int32\n",
      "dtypes: int32(15), int64(13)\n",
      "memory usage: 32.2 KB\n"
     ]
    }
   ],
   "source": [
    "ckd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1844e0b",
   "metadata": {},
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fd56192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(ckd, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2932c19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "affected\n",
       "1    91\n",
       "0    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.affected.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9166e44a",
   "metadata": {},
   "source": [
    "Addressing Data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d84de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is more than 10% difference between the count of classes, so it is a better approach to resample the training data\n",
    "cls0 = train_df[train_df['affected']==0]\n",
    "cls1 = train_df[train_df['affected']==1]\n",
    "from sklearn.utils import resample\n",
    "train_df_minority_resampled = resample(cls0, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=91,    \n",
    "                                 random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d6d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 28) (91, 28)\n"
     ]
    }
   ],
   "source": [
    "print(cls1.shape,train_df_minority_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0fe626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.concat([cls1,train_df_minority_resampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f965a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'affected'\n",
    "predictors = list(ckd.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1015a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_df[predictors]\n",
    "train_y = train_df[target] \n",
    "test_X = test_df[predictors]\n",
    "test_y = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca28eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb0b03",
   "metadata": {},
   "source": [
    "**Fitting Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "333e28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none', max_iter=900)\n",
    "_ = log_reg_model.fit(train_X, np.ravel(train_y))\n",
    "model_preds = log_reg_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "203b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liblinear Solver\n",
    "log_reg_liblin_model = LogisticRegression(solver='liblinear').fit(train_X, np.ravel(train_y))\n",
    "model_preds = log_reg_liblin_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"liblinear logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74246c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2 Regularization\n",
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(train_X, np.ravel(train_y))\n",
    "model_preds = log_reg_L2_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "01cee648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L1 Regularization\n",
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(train_X, np.ravel(train_y))\n",
    "model_preds = log_reg_L1_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26b8140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ElasticNet Regularization\n",
    "log_reg_elastic_model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1500)\n",
    "_ = log_reg_elastic_model.fit(train_X, np.ravel(train_y))\n",
    "model_preds = log_reg_elastic_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Elastic logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7833cc",
   "metadata": {},
   "source": [
    "**Fitting Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4ed60f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dt=DecisionTreeClassifier(max_depth=10)\n",
    "Dt=Dt.fit(train_X,np.ravel(train_y))\n",
    "model_preds=Dt.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ab3fc",
   "metadata": {},
   "source": [
    "**Fitting Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ed1567c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier()\n",
    "_ = rforest.fit(train_X, train_y)\n",
    "y_pred = rforest.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2276ff",
   "metadata": {},
   "source": [
    "**Fitting Ada Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c94e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier()\n",
    "_ = aboost.fit(train_X, train_y)\n",
    "y_pred = aboost.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"AdaBoost Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b097da",
   "metadata": {},
   "source": [
    "**Fitting Gradient Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f71b8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "_ = gboost.fit(train_X, train_y)\n",
    "y_pred = gboost.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Gradient Boost Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c18999",
   "metadata": {},
   "source": [
    "**Fitting Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ce345063",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(train_X, train_y)\n",
    "y_pred=ann.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Networks\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934f8a6",
   "metadata": {},
   "source": [
    "**Neural Networks using RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3958b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.01, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (40, 20), 'alpha': 0, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(60,40), (40,20), (60,50,40), (80,60,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_\n",
    "\n",
    "print(rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fe361c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(test_y, rand_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Networks Random Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fed45935",
   "metadata": {},
   "source": [
    "**Neural Networks using GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "840999bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (20,), (40,), (70,), (90,)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.1, .2, 1],\n",
    "    'learning_rate': ['adaptive', 'constant'],\n",
    "    'learning_rate_init': [ 0.01,0.2, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7966eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Networks Grid Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "38e8366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elastic logistic</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Networks</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Networks Grid Search</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Networks Random Search</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boost Classifier</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  Accuracy  Precision    Recall        F1\n",
       "0                    L1 logistic  1.000000   1.000000  1.000000  1.000000\n",
       "0               default logistic  0.983333   1.000000  0.972973  0.986301\n",
       "0             liblinear logistic  0.983333   1.000000  0.972973  0.986301\n",
       "0               Elastic logistic  0.983333   1.000000  0.972973  0.986301\n",
       "0                Neural Networks  0.983333   1.000000  0.972973  0.986301\n",
       "0    Neural Networks Grid Search  0.983333   1.000000  0.972973  0.986301\n",
       "0                    L2 logistic  0.966667   1.000000  0.945946  0.972222\n",
       "0  Neural Networks Random Search  0.966667   1.000000  0.945946  0.972222\n",
       "0       Decision Tree Classifier  0.900000   0.942857  0.891892  0.916667\n",
       "0                  Random Forest  0.900000   0.942857  0.891892  0.916667\n",
       "0            AdaBoost Classifier  0.900000   0.942857  0.891892  0.916667\n",
       "0      Gradient Boost Classifier  0.900000   0.942857  0.891892  0.916667"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by='Recall',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f7e7e",
   "metadata": {},
   "source": [
    "To identify which model is better for this dataset, Recall should be considered as the measure. The reason being it is a health related dataset and it's risky to have False Negatives i.e., predicting affected as 0 when it's 1 as it will result in death of patients if not treated.\n",
    "\n",
    "Above are the results of models fit on the dataset sorted by Recall, L1 logistic has fit the data better than other models. Followed by default,liblinear,Elastic Regression and Neural Networks. Out of the 3 neural networks that attempted to fit the data, Neural Networks and Neural Networks using Grid Search performed better than Neural Networks Random Search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80efb23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bp (Diastolic)', 'bp limit', 'sg', 'al', 'rbc', 'su', 'pc', 'pcc',\n",
       "       'ba', 'bgr', 'bu', 'sod', 'sc', 'pot', 'hemo', 'pcv', 'rbcc', 'wbcc',\n",
       "       'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'grf', 'stage', 'affected',\n",
       "       'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a234a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckd.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba8147b",
   "metadata": {},
   "source": [
    "**Wide Network using Keras Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17e7ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5a04e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a22fe1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 56.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(27))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # final layer, 1 category since it's a binary classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba71d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6f0f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[recall_m])\n",
    "\n",
    "#using the loss function as binary_crossentropy as this is binary classification\n",
    "#though metrics doesn't matter in fitting, but it does calculate the given metric at that loss point, \n",
    "# as I need recall to decide the best model,I took metric as recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef22718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 41ms/step - loss: 0.5912 - recall_m: 0.5426 - val_loss: 0.4888 - val_recall_m: 0.4397\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4168 - recall_m: 0.4299 - val_loss: 0.3985 - val_recall_m: 0.5201\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3428 - recall_m: 0.4536 - val_loss: 0.3788 - val_recall_m: 0.5201\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2973 - recall_m: 0.4531 - val_loss: 0.2969 - val_recall_m: 0.6183\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2778 - recall_m: 0.4858 - val_loss: 0.2716 - val_recall_m: 0.6719\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2517 - recall_m: 0.4896 - val_loss: 0.2542 - val_recall_m: 0.6183\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2369 - recall_m: 0.5024 - val_loss: 0.2517 - val_recall_m: 0.5714\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2161 - recall_m: 0.4801 - val_loss: 0.2528 - val_recall_m: 0.5558\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2064 - recall_m: 0.4863 - val_loss: 0.2259 - val_recall_m: 0.6183\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1981 - recall_m: 0.4948 - val_loss: 0.2269 - val_recall_m: 0.5714\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1896 - recall_m: 0.4673 - val_loss: 0.2393 - val_recall_m: 0.5558\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1837 - recall_m: 0.4815 - val_loss: 0.2156 - val_recall_m: 0.5871\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1732 - recall_m: 0.4815 - val_loss: 0.2016 - val_recall_m: 0.6183\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1677 - recall_m: 0.4825 - val_loss: 0.2014 - val_recall_m: 0.5871\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1624 - recall_m: 0.4867 - val_loss: 0.1923 - val_recall_m: 0.6183\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1562 - recall_m: 0.4938 - val_loss: 0.1800 - val_recall_m: 0.6183\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1523 - recall_m: 0.4792 - val_loss: 0.1742 - val_recall_m: 0.6183\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1466 - recall_m: 0.4825 - val_loss: 0.1899 - val_recall_m: 0.5871\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1418 - recall_m: 0.4815 - val_loss: 0.1681 - val_recall_m: 0.6183\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1386 - recall_m: 0.4796 - val_loss: 0.1710 - val_recall_m: 0.6183\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1352 - recall_m: 0.4839 - val_loss: 0.1626 - val_recall_m: 0.6183\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1347 - recall_m: 0.4801 - val_loss: 0.1607 - val_recall_m: 0.6183\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1284 - recall_m: 0.4848 - val_loss: 0.1672 - val_recall_m: 0.6183\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1263 - recall_m: 0.4995 - val_loss: 0.1679 - val_recall_m: 0.6027\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1231 - recall_m: 0.4796 - val_loss: 0.1569 - val_recall_m: 0.6183\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1203 - recall_m: 0.4844 - val_loss: 0.1555 - val_recall_m: 0.6183\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1168 - recall_m: 0.4773 - val_loss: 0.1570 - val_recall_m: 0.6183\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1154 - recall_m: 0.4773 - val_loss: 0.1480 - val_recall_m: 0.6183\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1122 - recall_m: 0.4830 - val_loss: 0.1558 - val_recall_m: 0.6027\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1112 - recall_m: 0.4844 - val_loss: 0.1522 - val_recall_m: 0.6183\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1082 - recall_m: 0.4796 - val_loss: 0.1445 - val_recall_m: 0.6183\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1056 - recall_m: 0.4891 - val_loss: 0.1440 - val_recall_m: 0.6183\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1042 - recall_m: 0.4848 - val_loss: 0.1569 - val_recall_m: 0.5848\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1029 - recall_m: 0.4844 - val_loss: 0.1427 - val_recall_m: 0.6183\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1017 - recall_m: 0.4825 - val_loss: 0.1420 - val_recall_m: 0.6183\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0990 - recall_m: 0.4796 - val_loss: 0.1483 - val_recall_m: 0.6027\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0971 - recall_m: 0.4867 - val_loss: 0.1383 - val_recall_m: 0.6183\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0954 - recall_m: 0.4820 - val_loss: 0.1385 - val_recall_m: 0.6183\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0924 - recall_m: 0.4867 - val_loss: 0.1387 - val_recall_m: 0.6183\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0907 - recall_m: 0.4801 - val_loss: 0.1336 - val_recall_m: 0.6183\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0899 - recall_m: 0.4848 - val_loss: 0.1371 - val_recall_m: 0.6027\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0904 - recall_m: 0.4848 - val_loss: 0.1345 - val_recall_m: 0.6183\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0865 - recall_m: 0.4943 - val_loss: 0.1294 - val_recall_m: 0.6183\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0866 - recall_m: 0.4853 - val_loss: 0.1375 - val_recall_m: 0.5848\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0839 - recall_m: 0.4848 - val_loss: 0.1284 - val_recall_m: 0.6183\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0839 - recall_m: 0.4920 - val_loss: 0.1316 - val_recall_m: 0.6027\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0812 - recall_m: 0.4825 - val_loss: 0.1259 - val_recall_m: 0.6183\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0804 - recall_m: 0.4872 - val_loss: 0.1252 - val_recall_m: 0.6183\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0799 - recall_m: 0.4943 - val_loss: 0.1224 - val_recall_m: 0.6183\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0778 - recall_m: 0.4972 - val_loss: 0.1270 - val_recall_m: 0.5848\n",
      "CPU times: total: 484 ms\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(train_X, train_y, validation_data=(test_X, test_y), \n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f69ff4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1270373910665512, 0.5848214626312256]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(test_X, test_y, verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee1c4044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13\n",
      "recall_m: 0.58\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], scores[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c63fec9f",
   "metadata": {},
   "source": [
    "**Deep Network using Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c7ac5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=27))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9edf84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02ad5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 0.6932 - recall_m: 0.3442 - val_loss: 0.6278 - val_recall_m: 0.3683\n",
      "Epoch 2/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5525 - recall_m: 0.4361 - val_loss: 0.5076 - val_recall_m: 0.5871\n",
      "Epoch 3/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4596 - recall_m: 0.5024 - val_loss: 0.4596 - val_recall_m: 0.5067\n",
      "Epoch 4/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3949 - recall_m: 0.4631 - val_loss: 0.3684 - val_recall_m: 0.6518\n",
      "Epoch 5/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3593 - recall_m: 0.4782 - val_loss: 0.3335 - val_recall_m: 0.7210\n",
      "Epoch 6/60\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3193 - recall_m: 0.5204 - val_loss: 0.2961 - val_recall_m: 0.6518\n",
      "Epoch 7/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2924 - recall_m: 0.5076 - val_loss: 0.2801 - val_recall_m: 0.6027\n",
      "Epoch 8/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2624 - recall_m: 0.4749 - val_loss: 0.2693 - val_recall_m: 0.5871\n",
      "Epoch 9/60\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2457 - recall_m: 0.4886 - val_loss: 0.2367 - val_recall_m: 0.6362\n",
      "Epoch 10/60\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2326 - recall_m: 0.4896 - val_loss: 0.2353 - val_recall_m: 0.5848\n",
      "Epoch 11/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2199 - recall_m: 0.4725 - val_loss: 0.2480 - val_recall_m: 0.5379\n",
      "Epoch 12/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2107 - recall_m: 0.4815 - val_loss: 0.2205 - val_recall_m: 0.5536\n",
      "Epoch 13/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1959 - recall_m: 0.4763 - val_loss: 0.1967 - val_recall_m: 0.6183\n",
      "Epoch 14/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1871 - recall_m: 0.4825 - val_loss: 0.1943 - val_recall_m: 0.6004\n",
      "Epoch 15/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1792 - recall_m: 0.4896 - val_loss: 0.1829 - val_recall_m: 0.6183\n",
      "Epoch 16/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1688 - recall_m: 0.4863 - val_loss: 0.1707 - val_recall_m: 0.6362\n",
      "Epoch 17/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1634 - recall_m: 0.4844 - val_loss: 0.1664 - val_recall_m: 0.6362\n",
      "Epoch 18/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1557 - recall_m: 0.5005 - val_loss: 0.1841 - val_recall_m: 0.5536\n",
      "Epoch 19/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1485 - recall_m: 0.4711 - val_loss: 0.1555 - val_recall_m: 0.6362\n",
      "Epoch 20/60\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1428 - recall_m: 0.4948 - val_loss: 0.1585 - val_recall_m: 0.6183\n",
      "Epoch 21/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1385 - recall_m: 0.4891 - val_loss: 0.1473 - val_recall_m: 0.6183\n",
      "Epoch 22/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1391 - recall_m: 0.4825 - val_loss: 0.1444 - val_recall_m: 0.6183\n",
      "Epoch 23/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1287 - recall_m: 0.4953 - val_loss: 0.1503 - val_recall_m: 0.6183\n",
      "Epoch 24/60\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1247 - recall_m: 0.4943 - val_loss: 0.1530 - val_recall_m: 0.6027\n",
      "Epoch 25/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1204 - recall_m: 0.4744 - val_loss: 0.1357 - val_recall_m: 0.6183\n",
      "Epoch 26/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1188 - recall_m: 0.5000 - val_loss: 0.1323 - val_recall_m: 0.6183\n",
      "Epoch 27/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1120 - recall_m: 0.4877 - val_loss: 0.1328 - val_recall_m: 0.6183\n",
      "Epoch 28/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1097 - recall_m: 0.4825 - val_loss: 0.1263 - val_recall_m: 0.6183\n",
      "Epoch 29/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1056 - recall_m: 0.4830 - val_loss: 0.1338 - val_recall_m: 0.6183\n",
      "Epoch 30/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1064 - recall_m: 0.4948 - val_loss: 0.1273 - val_recall_m: 0.6183\n",
      "Epoch 31/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1014 - recall_m: 0.4744 - val_loss: 0.1196 - val_recall_m: 0.6183\n",
      "Epoch 32/60\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0967 - recall_m: 0.4943 - val_loss: 0.1187 - val_recall_m: 0.6183\n",
      "Epoch 33/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0945 - recall_m: 0.4901 - val_loss: 0.1381 - val_recall_m: 0.5871\n",
      "Epoch 34/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0945 - recall_m: 0.4792 - val_loss: 0.1146 - val_recall_m: 0.6183\n",
      "Epoch 35/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0921 - recall_m: 0.4773 - val_loss: 0.1162 - val_recall_m: 0.6183\n",
      "Epoch 36/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0877 - recall_m: 0.4976 - val_loss: 0.1288 - val_recall_m: 0.5871\n",
      "Epoch 37/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0858 - recall_m: 0.4920 - val_loss: 0.1095 - val_recall_m: 0.6183\n",
      "Epoch 38/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0839 - recall_m: 0.4872 - val_loss: 0.1085 - val_recall_m: 0.6183\n",
      "Epoch 39/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0789 - recall_m: 0.4896 - val_loss: 0.1085 - val_recall_m: 0.6183\n",
      "Epoch 40/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0765 - recall_m: 0.4801 - val_loss: 0.1045 - val_recall_m: 0.6183\n",
      "Epoch 41/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0751 - recall_m: 0.4848 - val_loss: 0.1140 - val_recall_m: 0.6027\n",
      "Epoch 42/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0774 - recall_m: 0.4953 - val_loss: 0.1052 - val_recall_m: 0.6183\n",
      "Epoch 43/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0718 - recall_m: 0.4943 - val_loss: 0.1013 - val_recall_m: 0.6183\n",
      "Epoch 44/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0711 - recall_m: 0.4853 - val_loss: 0.1118 - val_recall_m: 0.6027\n",
      "Epoch 45/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0678 - recall_m: 0.4848 - val_loss: 0.0973 - val_recall_m: 0.6183\n",
      "Epoch 46/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0682 - recall_m: 0.4920 - val_loss: 0.1028 - val_recall_m: 0.6183\n",
      "Epoch 47/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0649 - recall_m: 0.4848 - val_loss: 0.0949 - val_recall_m: 0.6183\n",
      "Epoch 48/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0634 - recall_m: 0.4848 - val_loss: 0.0936 - val_recall_m: 0.6183\n",
      "Epoch 49/60\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0632 - recall_m: 0.4943 - val_loss: 0.0937 - val_recall_m: 0.6183\n",
      "Epoch 50/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0606 - recall_m: 0.4920 - val_loss: 0.0967 - val_recall_m: 0.6183\n",
      "Epoch 51/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0594 - recall_m: 0.4848 - val_loss: 0.0921 - val_recall_m: 0.6183\n",
      "Epoch 52/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0568 - recall_m: 0.4920 - val_loss: 0.0905 - val_recall_m: 0.6183\n",
      "Epoch 53/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0561 - recall_m: 0.4924 - val_loss: 0.0930 - val_recall_m: 0.6183\n",
      "Epoch 54/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0557 - recall_m: 0.4991 - val_loss: 0.0943 - val_recall_m: 0.6004\n",
      "Epoch 55/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0538 - recall_m: 0.4830 - val_loss: 0.0964 - val_recall_m: 0.5848\n",
      "Epoch 56/60\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0514 - recall_m: 0.4901 - val_loss: 0.0856 - val_recall_m: 0.6183\n",
      "Epoch 57/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0508 - recall_m: 0.4948 - val_loss: 0.0824 - val_recall_m: 0.6183\n",
      "Epoch 58/60\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0497 - recall_m: 0.4877 - val_loss: 0.0837 - val_recall_m: 0.6183\n",
      "Epoch 59/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0492 - recall_m: 0.4924 - val_loss: 0.0838 - val_recall_m: 0.6183\n",
      "Epoch 60/60\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0484 - recall_m: 0.5019 - val_loss: 0.0802 - val_recall_m: 0.6183\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_X, train_y, \n",
    "                    validation_data=(test_X, test_y), \n",
    "                    epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "927b2630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08\n",
      "recall_m: 0.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = model.evaluate(test_X, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f\" % (model.metrics_names[1], scores[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bf9489d",
   "metadata": {},
   "source": [
    "**RandomGridSearch**\n",
    "*(Keras with Sklearn tuning)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2815a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = recall_m\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=27)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = [recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "261b7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=150,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39e796ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.005, 0.01],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 50, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",\"sgd\"]\n",
    "}\n",
    "keras_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d26bcbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001ED12EC5310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001ED140DBB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 512us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='recall', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_recall', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(train_X, train_y, callbacks=callback, verbose=0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "767bd66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.0005,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (90,),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 100}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "475e6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.0005, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (90,), 'model__dropout': 0.1, 'epochs': 100, 'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "360ded48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        23\n",
      "           1       1.00      0.97      0.99        37\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.99      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 96.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(test_X)\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a35b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972972972972973"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_y, best_net.predict(test_X))                                     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7022763",
   "metadata": {},
   "source": [
    "NN Model                     Recall\n",
    "\n",
    "Wide NN                      0.58\n",
    "Deep NN                      0.62\n",
    "NN using RandomSearch CV     0.97\n",
    "\n",
    "As part of Assignment 1, I have fit various classification models on the Chronic Kidney Disease Dataset. As this is a health related dataset, I have considered Recall as the evaluation metric to find the best fitting model. L1 Logistic has a Recall value of 1 and has fit the data better than the remaining models. Now out of MLPClassifier, Wide Network using Keras, Deep Network using Keras and Network using Keras RandomSearch with Sklearn Tuning- the RandomSearch with Sklearn Tuning and MLP Classifier has fit the data at the same level and is next to L1 logistic in the list."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
